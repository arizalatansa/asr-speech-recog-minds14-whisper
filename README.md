![ASR MINDS14](https://github.com/arizalatansa/asr-speech-recog-minds14-whisper/assets/108741841/49767712-6dcf-45fe-b74c-9896a20a2cf1)

In the pulsating world of digital technology, Automatic Speech Recognition (ASR) has emerged as a crucial element in applications that thrive on voice interaction. This project embarks on a journey to explore the utilization of pretrained ASR models, with a special focus on the Whisper-tiny model, for speech recognition tasks using the MIN-DS14 dataset. The Whisper-tiny model, renowned for its prowess in reducing size and accelerating inference, is a perfect fit for devices with resource constraints. The MINDS14 dataset, has  across languages in their datasets, but only 3 english sub-datasets we are going to use. The MINDS14 a treasure trove of language and accent variations, poses a formidable challenge to ASR models in deciphering the subtle variations and nuances in everyday speech. By marrying these two components, this research harbors the ambition to enhance speech recognition accuracy and shed light on the constraints and possibilities of pretrained ASR models in real-world application scenarios.

# asr-speech-recog-minds14-whisper
